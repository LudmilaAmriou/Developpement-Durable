from Exercices_Debutant.supprimer_doublons import supprimer_doublons
import time

def run_tests():
    print("="*50)
    print("üß™ ECO-CODING TESTS - Suppression Doublons")
    print("="*50)
    
    # Test 1: Correctness - basic functionality
    print("\n1Ô∏è‚É£ Test de correction...")
    test_cases = [
        (['a.txt', 'b.txt', 'a.txt', 'c.txt'], ['a.txt', 'b.txt', 'c.txt']),
        (['x', 'x', 'x'], ['x']),
        (['a', 'b', 'c'], ['a', 'b', 'c']),
        ([], []),
        (['z'], ['z']),
    ]
    
    try:
        for input_list, expected in test_cases:
            result = supprimer_doublons(input_list)
            assert result == expected, f"Failed on {input_list}: got {result}, expected {expected}"
        print("   ‚úÖ Correction OK")
    except AssertionError as e:
        print(f"   ‚ùå Erreur: {e}")
        return
    
    # Test 2: Order preservation (critical for this exercise)
    print("\n2Ô∏è‚É£ Test de pr√©servation de l'ordre...")
    test_order = ['z', 'a', 'z', 'b', 'a', 'c']
    result_order = supprimer_doublons(test_order)
    expected_order = ['z', 'a', 'b', 'c']  # First occurrence kept
    
    try:
        assert result_order == expected_order, f"Order not preserved: {result_order}"
        print("   ‚úÖ Ordre pr√©serv√© correctement")
    except AssertionError as e:
        print(f"   ‚ùå {e}")
        return
    
    # Test 3: Complexity Detection - O(n¬≤) vs O(n)
    print("\n3Ô∏è‚É£ Analyse de complexit√©...")
    print("   ‚Üí Test avec beaucoup de doublons (pire cas)")
    
    sizes = [1000, 2000, 4000, 8000]
    times = []
    
    for size in sizes:
        # WORST CASE: Maximum unique files (no early duplicates to skip)
        # This forces EVERY iteration to scan the full growing list
        test_list = []
        for i in range(size):
            # Each file is unique, so every 'if f not in res' scans all of res
            test_list.append(f'unique_file_{i}.txt')
        
        # Measure time
        measurements = []
        for _ in range(3):
            start = time.perf_counter()
            supprimer_doublons(test_list)
            end = time.perf_counter()
            measurements.append(end - start)
        
        median_time = sorted(measurements)[1]
        times.append(median_time)
        print(f"   Size {size:5d}: {median_time*1000:8.2f} ms")
    
    # Analyze growth rate
    print("\n4Ô∏è‚É£ Analyse du ratio de croissance...")
    
    ratios = []
    for i in range(len(times) - 1):
        ratio = times[i+1] / times[i]
        size_ratio = sizes[i+1] / sizes[i]
        ratios.append(ratio)
        print(f"   {sizes[i]:5d} ‚Üí {sizes[i+1]:5d}: temps x{ratio:.2f} (taille x{size_ratio:.1f})")
    
    avg_ratio = sum(ratios) / len(ratios)
    
    # Check absolute performance
    print(f"\n‚è±Ô∏è  Temps absolu ({sizes[-1]} fichiers): {times[-1]*1000:.2f} ms")
    
    # Final scoring
    print("\n" + "="*50)
    print("üìä R√âSULTAT FINAL")
    print("="*50)
    
    # Detect complexity based on growth pattern
    if avg_ratio <= 2.3:
        # Linear O(n) - optimal with set or dict
        print("‚úÖ TR√àS √âCOLO - Complexit√© O(n) d√©tect√©e!")
        print("   ‚Üí Tu utilises probablement dict ou set")
        print("   ‚Üí Algorithme optimal tout en pr√©servant l'ordre!")
        eco_score = 100
        
    elif avg_ratio <= 3.0:
        # Slightly suboptimal
        print("‚ö†Ô∏è  PRESQUE OPTIMAL")
        print("   ‚Üí Complexit√© proche de O(n)")
        print("   ‚Üí Peut-√™tre quelques op√©rations en trop?")
        eco_score = 75
        
    elif avg_ratio >= 3.5:
        # Quadratic O(n¬≤) detected!
        print("‚ùå PAS √âCOLO - Complexit√© O(n¬≤) d√©tect√©e!")
        print("   ‚Üí Probl√®me: 'if f not in res' parcourt toute la liste!")
        print("   ‚Üí √Ä chaque it√©ration, Python scanne res du d√©but √† la fin")
        print(f"   ‚Üí Avec {sizes[-1]} fichiers: {sizes[-1]**2/1000000:.1f} millions de comparaisons! üò±")
        print()
        eco_score = 30
        
    else:
        print("‚ö†Ô∏è  COMPLEXIT√â AMBIGU√ã")
        print(f"   ‚Üí Ratio moyen: {avg_ratio:.2f}")
        eco_score = 50
    
    # Additional performance check
    if times[-1] > 0.8:  # More than 800ms for 8000 unique files
        print(f"\n‚ö†Ô∏è  WARNING: Trop lent en pratique!")
        print(f"   ‚Üí {times[-1]:.2f}s pour {sizes[-1]} fichiers")
        print(f"   ‚Üí Avec 100,000 fichiers, √ßa prendrait {times[-1] * (100000/sizes[-1])**2 / 60:.1f} MINUTES!")
        eco_score = min(eco_score, 20)
    
    elif times[-1] > 0.3:
        print(f"\n‚ö†Ô∏è  Lent pour des grandes listes")
        print(f"   ‚Üí {times[-1]*1000:.0f}ms pour {sizes[-1]} fichiers")
        eco_score = min(eco_score, 35)
    
    print(f"\nüí° CONSEIL ECO:")
    if eco_score < 80:
        print("   Le probl√®me avec ton code:")
        print("   ‚ùå 'if f not in res' sur une liste est O(n)")
        print("   ‚ùå Pour chaque fichier, tu scannes toute la liste res")
        print("   ‚ùå Complexit√© totale: O(n √ó n) = O(n¬≤)")
        print()
        print("   Solutions optimales O(n):")
        print()
        print("   üí° Solution 1: Set pour tracker (le plus simple)")
        print()
        print("   üí° Solution 2: dict.fromkeys() (Pythonic)")
        print("        ‚Üí dict garde l'ordre en Python 3.7+")
        print("        ‚Üí Une seule ligne!")
        print()
        print("   Gain: O(n) vs O(n¬≤)")
        print("   ‚Üí Avec 10,000 fichiers: 10,000 ops vs 100 millions!")
    
    print(f"\nüå± ECO-SCORE: {eco_score}/100")
    
    if eco_score >= 90:
        print("üèÜ Parfait! D√©duplication ultra-optimis√©e!")
    elif eco_score >= 70:
        print("üëç Bon travail! Proche de l'optimal")
    elif eco_score >= 40:
        print("‚ö†Ô∏è  Fonctionne mais O(n¬≤) est trop lent!")
    else:
        print("üìö Utilise un set ou dict pour O(1) lookup!")
    
    return eco_score >= 60

if __name__ == "__main__":
    run_tests()