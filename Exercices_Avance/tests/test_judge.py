#!/usr/bin/env python3
"""
JUGE GLOBAL - Exercices Avanc√©
Ex√©cute tous les tests et calcule le score √©cologique moyen
G√©n√®re un rapport Markdown
"""

import sys
import importlib
from datetime import datetime

# Liste des tests Avanc√©
AVANCE_TESTS = [
    'Exercices_Avance.tests.test_fusion_listes',
    'Exercices_Avance.tests.test_trouver_sous_sequence',
]

def generate_markdown_report(results, avg_score, passed):
    """G√©n√®re un rapport Markdown"""
    
    # D√©termination de la note
    if avg_score >= 90:
        grade = "A+"
        badge = "üèÜ"
        badge_color = "brightgreen"
        comment = "EXCELLENT! Code ultra-optimis√©!"
    elif avg_score >= 80:
        grade = "A"
        badge = "üåü"
        badge_color = "green"
        comment = "Tr√®s bon travail! Quelques optimisations possibles"
    elif avg_score >= 70:
        grade = "B"
        badge = "üëç"
        badge_color = "yellowgreen"
        comment = "Bon niveau, continue d'optimiser"
    elif avg_score >= 60:
        grade = "C"
        badge = "‚ö†Ô∏è"
        badge_color = "yellow"
        comment = "Passable - Beaucoup d'am√©liorations n√©cessaires"
    elif avg_score >= 50:
        grade = "D"
        badge = "üò¨"
        badge_color = "orange"
        comment = "Insuffisant - Revois les algorithmes"
    else:
        grade = "F"
        badge = "üíÄ"
        badge_color = "red"
        comment = "√âCHEC - Algorithmes catastrophiques!"
    
    # G√©n√©ration du Markdown
    md = f"""# Rapport √âco-Coding - Exercices Avanc√©

![Score](https://img.shields.io/badge/Score-{int(avg_score)}%25-{badge_color}?style=for-the-badge)
![Grade](https://img.shields.io/badge/Note-{grade.replace('+', '%2B')}-{badge_color}?style=for-the-badge)
![Status](https://img.shields.io/badge/Status-{'VALID√â' if passed else '√âCHOU√â'}-{'success' if passed else 'critical'}?style=for-the-badge)

**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Niveau:** Avanc√©  
**Moyenne:** {avg_score:.1f}/100  
**Note:** {grade}

---

## R√©sultat Global

> {comment}

**Validation:** {"Exercices VALID√âS" if passed else "Exercices NON VALID√âS"}

---

## Scores D√©taill√©s

| Exercice | Score | Status | Barre de Progression |
|----------|-------|--------|---------------------|
"""
    
    # Ajout de chaque exercice
    for exercise, score in results.items():
        status = "OK" if score >= 60 else "FAIL"
        filled = int(score / 5)
        bar = "‚ñà" * filled + "‚ñë" * (20 - filled)
        md += f"| `{exercise}` | **{score:.0f}/100** | {status} | {bar} |\n"
    
    md += """
---

## üå± Impact √âcologique

"""
    
    if avg_score >= 80:
        md += """### ‚úÖ Excellent Impact!
Ton code √©conomise beaucoup d'√©nergie! Continue comme √ßa! üåç
- Algorithmes optimaux utilis√©s
- Faible consommation CPU
- Empreinte carbone minimale
"""
    elif avg_score >= 60:
        md += """### ‚ö†Ô∏è Impact Mod√©r√©
Ton code fonctionne mais peut √™tre plus efficace.
- Quelques algorithmes √† optimiser
- Consommation CPU moyenne
- Chaque optimisation = moins d'√©nergie consomm√©e üí°
"""
    else:
        md += """### ‚ùå Impact √âlev√©!
Ton code gaspille BEAUCOUP d'√©nergie!
- Algorithmes inefficaces d√©tect√©s
- Forte consommation CPU
- Empreinte carbone importante üè≠
- **ACTION REQUISE:** Optimise tes algorithmes!
"""
    
    md += """
---

## Exercices par Score

"""
    
    # Groupement par score
    excellent = [k for k, v in results.items() if v >= 90]
    good = [k for k, v in results.items() if 70 <= v < 90]
    passable = [k for k, v in results.items() if 60 <= v < 70]
    failing = [k for k, v in results.items() if v < 60]
    
    if excellent:
        md += "### Excellent (‚â•90)\n"
        for ex in excellent:
            md += f"- `{ex}` ({results[ex]:.0f}/100)\n"
        md += "\n"
    
    if good:
        md += "### Bon (70-89)\n"
        for ex in good:
            md += f"- `{ex}` ({results[ex]:.0f}/100)\n"
        md += "\n"
    
    if passable:
        md += "### Passable (60-69)\n"
        for ex in passable:
            md += f"- `{ex}` ({results[ex]:.0f}/100)\n"
        md += "\n"
    
    if failing:
        md += "### √Ä Refaire (<60)\n"
        for ex in failing:
            md += f"- `{ex}` ({results[ex]:.0f}/100) - **OPTIMISATION REQUISE**\n"
        md += "\n"
    
    md += """
---

## Recommandations

"""
    
    if avg_score < 60:
        md += """### Priorit√©: Revoir les algorithmes avanc√©s
1. √âtudie les algorithmes classiques (merge, binary search, etc.)
2. Identifie les complexit√©s O(n¬≤) et O(n√óm)
3. Exploite les propri√©t√©s des donn√©es (d√©j√† tri√©, etc.)
4. Pense "divide and conquer" et optimisations

"""
    elif avg_score < 80:
        md += """### Am√©liorations possibles
1. Optimise les exercices avec score < 80
2. Compare ton code avec les solutions optimales
3. Cherche les optimisations O(n) vs O(n log n)
4. √âvite les copies inutiles et les slicing en boucle

"""
    else:
        md += """### Continue sur ta lanc√©e!
1. Excellent niveau atteint!
2. Tu ma√Ætrises les algorithmes avanc√©s!
3. Pr√™t pour le niveau Expert!
4. Tu contribues √† un code plus √©cologique!

"""
    
    md += """---

## Prochaines √âtapes

"""
    
    if passed:
        md += """- Exercices Avanc√© valid√©s!
- Tu peux passer aux **Exercices Expert**
- Ou am√©liorer tes scores existants pour viser le 100/100
- Le niveau Expert te mettra face aux algorithmes les plus complexes!
"""
    else:
        md += """- Retravaille les exercices avec score < 60
- Retente le test une fois optimis√©
- Objectif: Moyenne ‚â• 60/100
"""
    
    md += f"""
---

<div align="center">

**Rapport g√©n√©r√© automatiquement le {datetime.now().strftime('%d/%m/%Y √† %H:%M')}**  
üå± *Code √©cologique = Plan√®te pr√©serv√©e* üåç


</div>
"""
    
    return md

def run_all_tests():
    """Ex√©cute tous les tests et collecte les scores"""
    print("="*70)
    print(" JUGE GLOBAL - EXERCICES AVANC√â - √âCO-CODING")
    print("="*70)
    print()
    
    results = {}
    total_score = 0
    
    for test_module_name in AVANCE_TESTS:
        exercise_name = test_module_name.split('.')[-1].replace('test_', '')
        
        print(f"\n{'='*70}")
        print(f" TEST: {exercise_name}")
        print(f"{'='*70}\n")
        
        try:
            test_module = importlib.import_module(test_module_name)
            score = test_module.run_tests()
            results[exercise_name] = score
            total_score += score
            print(f"\n {exercise_name}: {score}/100")
            
        except Exception as e:
            print(f"\n{exercise_name}: ERREUR - {e}")
            results[exercise_name] = 0
    
    # Calcul de la moyenne
    num_tests = len(AVANCE_TESTS)
    avg_score = total_score / num_tests if num_tests > 0 else 0
    
    # Rapport console
    print("\n" + "="*70)
    print("RAPPORT FINAL")
    print("="*70)
    print()
    
    print("Scores par exercice:")
    for exercise, score in results.items():
        status = "‚úÖ" if score >= 60 else "‚ùå"
        bar = "‚ñà" * int(score / 5) + "‚ñë" * (20 - int(score / 5))
        print(f"  {status} {exercise:30s} [{bar}] {score:3.0f}/100")
    
    print()
    print(f"Score total: {total_score:.0f}/{num_tests * 100}")
    print(f"Moyenne:     {avg_score:.1f}/100")
    print()
    
    # D√©termination de la note
    if avg_score >= 90:
        grade, emoji = "A+", "üèÜ"
        comment = "EXCELLENT! Code ultra-optimis√©!"
    elif avg_score >= 80:
        grade, emoji = "A", "üåü"
        comment = "Tr√®s bon travail!"
    elif avg_score >= 70:
        grade, emoji = "B", "üëç"
        comment = "Bon niveau"
    elif avg_score >= 60:
        grade, emoji = "C", "‚ö†Ô∏è"
        comment = "Passable"
    elif avg_score >= 50:
        grade, emoji = "D", "üò¨"
        comment = "Insuffisant"
    else:
        grade, emoji = "F", "üíÄ"
        comment = "√âCHEC"
    
    print("="*70)
    print(f"{emoji} NOTE FINALE: {grade} ({avg_score:.1f}/100)")
    print(f"{emoji} {comment}")
    print("="*70)
    print()
    
    passed = avg_score >= 60
    
    if passed:
        print("VALIDATION: Exercices valid√©s")
        print(f"   ‚Üí {len([s for s in results.values() if s >= 60])}/{num_tests} exercices au-dessus de 60/100")
    else:
        print("VALIDATION: Exercices NON valid√©s")
        print(f"   ‚Üí Moyenne insuffisante ({avg_score:.1f}/100)")
        print(f"   ‚Üí Minimum requis: 60/100")
    
    print()
    
    # Impact √©cologique
    print("üå± IMPACT √âCOLOGIQUE:")
    if avg_score >= 80:
        print("   Ton code √©conomise beaucoup d'√©nergie!")
        print("   Continue comme √ßa!")
    elif avg_score >= 60:
        print("   Ton code fonctionne mais peut √™tre plus efficace")
        print("   Chaque optimisation = moins d'√©nergie consomm√©e")
    else:
        print("   Ton code gaspille BEAUCOUP d'√©nergie!")
        print("   Algorithmes inefficaces = forte empreinte carbone")
    
    print()
    
    # G√©n√©ration du rapport Markdown
    print("G√©n√©ration du rapport...")
    report_md = generate_markdown_report(results, avg_score, passed)
    
    report_filename = "ECO_REPORT_AVANCE.md"
    try:
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(report_md)
        print(f"Rapport g√©n√©r√©: {report_filename}")
        print(f"   ‚Üí Ouvre ce fichier pour voir ton rapport d√©taill√©!")
    except Exception as e:
        print(f"Erreur lors de la g√©n√©ration du rapport: {e}")
    
    print()
    print("="*70)
    
    return 0 if passed else 1

if __name__ == "__main__":
    exit_code = run_all_tests()
    sys.exit(exit_code)